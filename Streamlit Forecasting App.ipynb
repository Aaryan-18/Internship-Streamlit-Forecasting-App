{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import (is_categorical_dtype, is_datetime64_any_dtype,is_numeric_dtype, is_object_dtype,)   \n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Title of the WebApp, Process in the Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 11:21:22.600 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\MU_ICT_005\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "st.title('AIPL Time Series Forecasting App')\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload the excel file (having '.xlsx' extension)\")\n",
    "if uploaded_file is not None:\n",
    "    sheet = st.text_input(\"Enter Sheet name in which the required data is present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the uploaded Excel and store it in Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if uploaded_file is not None:\n",
    "    try:\n",
    "        df_in = pd.read_excel(uploaded_file, sheet_name=sheet)\n",
    "    except:\n",
    "        st.warning('Please enter a valid sheet name')\n",
    "        \n",
    "else:\n",
    "    st.warning(\"Upload an Excel file with '.xlsx' extension.\")\n",
    "\n",
    "if 'df_in' in globals():\n",
    "    st.write(f'Shape of input dataframe is {df_in.shape[0]} rows x {df_in.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the Input Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_in' in globals():\n",
    "    st.subheader(\"Filtering the Input Dataframe\")\n",
    "    \n",
    "    df_fil = df_in.copy()\n",
    "    modify = st.selectbox(\"Do you want to Filter the Dataframe?\", [\"No\",\"Yes\"])\n",
    "    \n",
    "    if modify==\"Yes\":                  # Filtering Streamlit dataframe code taken from tylerjrichards/st-filter-dataframe repository on GitHub \n",
    "\n",
    "        # Try to convert datetimes into a standard format (datetime, no timezone)\n",
    "        for col in df_fil.columns:\n",
    "            if is_object_dtype(df_fil[col]):\n",
    "                try:\n",
    "                    df_fil[col] = pd.to_datetime(df_fil[col])\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            if is_datetime64_any_dtype(df_fil[col]):\n",
    "                df_fil[col] = df_fil[col].dt.tz_localize(None)\n",
    "\n",
    "        modification_container = st.container()\n",
    "\n",
    "        with modification_container:\n",
    "            to_filter_columns = st.multiselect(\"Filter dataframe on\", df_fil.columns)\n",
    "            for column in to_filter_columns:\n",
    "                left, right = st.columns((1, 20))\n",
    "                left.write(\"↳\")\n",
    "                # Treat columns with < 10 unique values as categorical\n",
    "                if is_categorical_dtype(df_fil[column]) or df_fil[column].nunique() < 10:\n",
    "                    user_cat_input = right.multiselect(\n",
    "                        f\"Values for {column}\",\n",
    "                        df_fil[column].unique(),\n",
    "                        default=list(df_fil[column].unique()),\n",
    "                    )\n",
    "                    df_fil = df_fil[df_fil[column].isin(user_cat_input)]\n",
    "                elif is_numeric_dtype(df_fil[column]):\n",
    "                    _min = float(df_fil[column].min())\n",
    "                    _max = float(df_fil[column].max())\n",
    "                    step = (_max - _min) / 100\n",
    "                    user_num_input = right.slider(\n",
    "                        f\"Values for {column}\",\n",
    "                        _min,\n",
    "                        _max,\n",
    "                        (_min, _max),\n",
    "                        step=step,\n",
    "                    )\n",
    "                    df_fil = df_fil[df_fil[column].between(*user_num_input)]\n",
    "                elif is_datetime64_any_dtype(df_fil[column]):\n",
    "                    user_date_input = right.date_input(\n",
    "                        f\"Values for {column}\",\n",
    "                        value=(\n",
    "                            df_fil[column].min(),\n",
    "                            df_fil[column].max(),\n",
    "                        ),\n",
    "                    )\n",
    "                    if len(user_date_input) == 2:\n",
    "                        user_date_input = tuple(map(pd.to_datetime, user_date_input))\n",
    "                        start_date, end_date = user_date_input\n",
    "                        df_fil = df_fil.loc[df_fil[column].between(start_date, end_date)]\n",
    "                else:\n",
    "                    user_text_input = right.text_input(\n",
    "                        f\"Text string in {column}\",\n",
    "                    )\n",
    "                    if user_text_input:\n",
    "                        df_fil = df_fil[df_fil[column].str.contains(user_text_input)]                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the datetime column using Streamlit selectbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_fil' in globals():\n",
    "    st.subheader('Selecting the Time Series')\n",
    "    date_col = st.selectbox(\"Choose the Datetime column of the dataframe\", list(df_fil.columns) )\n",
    "\n",
    "    if ('date_col' in globals()) and (date_col is not None):\n",
    "        try:\n",
    "            df_fil[date_col] = pd.to_datetime(df_fil[date_col])            # convert into datetime type\n",
    "            ds = df_fil[date_col]\n",
    "        except:\n",
    "            st.warning('Column chosen is not a datetime column. Please choose a datetime column') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the Time Series, after column selection and if required, aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_fil' in globals() and df_fil[date_col].dtype=='datetime64[ns]':\n",
    "    choice1 = st.selectbox(\"Do you want to Forecast the 'Daily'/'Monthly'/'Yearly' Count or Values of a Dataframe column?\", ['Count', 'Dataframe Column Values'])\n",
    "    \n",
    "    if choice1=='Count':\n",
    "        choice3 = st.selectbox(\"Choose the Period for the count, which should be forecasted.\", ['Monthly','Yearly','Daily'] )\n",
    "    elif choice1=='Dataframe Column Values':\n",
    "        choice2 = st.selectbox(\"Choose the column which is to be Forecasted\", list(df_fil.columns))\n",
    "        choice3 = st.selectbox(\"Choose the Period for the count, which should be forecasted.\", ['Monthly','Yearly','Daily'] )\n",
    "        \n",
    "        choice4 = st.selectbox(\"Select the suitable method for aggregation\", ['Mean', 'Sum'])\n",
    "    \n",
    "    \n",
    "    if choice1 == 'Count':\n",
    "        df_t = df_fil.iloc[:,0]                      # any column can be selected as we just want to count the entries in each period\n",
    "        df_t.index = df_fil[date_col]                # indexing dataframe with datetime column is necessary for using resample function\n",
    "        \n",
    "        if choice3== 'Daily':\n",
    "            time_series = df_t.resample('D').count()        # Resample the df to get daily/weekly/yearly values for time series\n",
    "        elif choice3=='Monthly':    \n",
    "            time_series = df_t.resample('M').count()\n",
    "        else:\n",
    "            time_series = df_t.resample('Y').count()\n",
    "\n",
    "    elif choice1=='Dataframe Column Values':\n",
    "        df_t = df_fil[choice2]                              \n",
    "        df_t.index = df_fil[date_col]\n",
    "        \n",
    "        try:\n",
    "            if choice3== 'Daily':\n",
    "                if choice4 == 'Sum':\n",
    "                    time_series = df_t.resample('D').sum()\n",
    "                else:\n",
    "                    time_series = df_t.resample('D').mean()\n",
    "            elif choice3=='Monthly':    \n",
    "                if choice4 == 'Sum':\n",
    "                    time_series = df_t.resample('M').sum()\n",
    "                else:\n",
    "                    time_series = df_t.resample('M').mean()\n",
    "            else:\n",
    "                if choice4 == 'Sum':\n",
    "                    time_series = df_t.resample('Y').sum() \n",
    "                else:\n",
    "                    time_series = df_t.resample('Y').mean()\n",
    "        \n",
    "            time_series = time_series.ffill()       # any NA value will be filled with the closest preceding non NA value\n",
    "        \n",
    "        except:\n",
    "            st.warning('Please choose a Column with float or int datatype for Forecasting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'time_series' in globals():\n",
    "    st.subheader(\"Removing Outliers\")\n",
    "    outlier_choice = st.selectbox('Do you want to remove outliers, if present?', ['No','Yes'])\n",
    "    \n",
    "    if outlier_choice==\"Yes\":\n",
    "        # Calculate the upper and lower limits\n",
    "        Q1 = time_series.quantile(0.25)\n",
    "        Q3 = time_series.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_lim = float(Q1 - 1.5*IQR)\n",
    "        upper_lim = float(Q3 + 1.5*IQR)\n",
    "        \n",
    "        # Create arrays of Boolean values indicating the outlier rows\n",
    "        outlier_indices_upp = np.where(time_series >= upper_lim)[0]\n",
    "        outlier_indices_low = np.where(time_series <= lower_lim)[0]\n",
    "        \n",
    "        # Replace the Outliers\n",
    "        time_series = time_series.replace(to_replace= list(time_series[outlier_indices_upp]), value= upper_lim)\n",
    "        time_series = time_series.replace(to_replace= list(time_series[outlier_indices_low]), value = lower_lim)\n",
    "        \n",
    "        st.write('Outliers removed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm Time Series choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'time_series' in globals():\n",
    "    st.subheader('Confirming Time Series')\n",
    "    confirm_choice = st.selectbox('Is this the data you want Forecasted?', ['No','Yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'confirm_choice' in globals() and confirm_choice=='Yes':     \n",
    "    st.header('Time Series Graph')\n",
    "    \n",
    "    # Assigning y label\n",
    "    if choice1=='Count':\n",
    "        ylab = 'Count'\n",
    "    else:\n",
    "        ylab = choice2\n",
    "    \n",
    "    fig1 = plt.figure(figsize=(8,4))\n",
    "    plt.plot(time_series)\n",
    "    plt.title(\"Original Time Series\")\n",
    "    plt.xlabel(date_col)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    st.pyplot(fig1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition of Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'confirm_choice' in globals() and confirm_choice=='Yes':\n",
    "    st.header('Seasonal Decomposition Graph')\n",
    "    \n",
    "    # Performing and Plotting seasonal decomposition\n",
    "    stl_result = seasonal_decompose(time_series, model='additive', period=12, extrapolate_trend=2)  # Assuming a seasonal period of 12 for monthly data\n",
    "\n",
    "    fig2, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=True, figsize=(10, 8))\n",
    "    \n",
    "    # Original time series\n",
    "    ax1.plot(time_series.index, time_series)\n",
    "    ax1.set_title('Original Time Series')\n",
    "    \n",
    "    # Trend component\n",
    "    ax2.plot(time_series.index, stl_result.trend)\n",
    "    ax2.set_title('Trend Component')\n",
    "    \n",
    "    # Seasonal component\n",
    "    ax3.plot(time_series.index, stl_result.seasonal)\n",
    "    ax3.set_title('Seasonal Component')\n",
    "    \n",
    "    # Residual component (noise)\n",
    "    ax4.plot(time_series.index, stl_result.resid)\n",
    "    ax4.set_title('Residual Component')\n",
    "    plt.xticks(rotation=45)\n",
    "    fig2.supxlabel(date_col)\n",
    "    fig2.supylabel(ylab)\n",
    "    \n",
    "    st.pyplot(fig2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'confirm_choice' in globals() and confirm_choice=='Yes':\n",
    "    st.header('Forecasting using Prophet Model')\n",
    "    df_prophet = pd.DataFrame( data = [time_series.index, time_series]).T\n",
    "    df_prophet.columns = ['ds','y']\n",
    "\n",
    "    # Converting 'ds' from object datatype to datetime format\n",
    "    df_prophet['ds'] = pd.to_datetime(df_prophet['ds'], format='%d-%m-%Y')\n",
    "    \n",
    "    per1 = st.slider('Please choose the number of periods for which Prophet Forecasting is to be done', min_value=0, max_value=50, value = 12)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the Forecast values and then Plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'confirm_choice' in globals() and confirm_choice=='Yes':\n",
    "    # Initialise and Fit the Prophet model to the data\n",
    "    prophet_model = Prophet()\n",
    "    prophet_model.fit(df_prophet)\n",
    "\n",
    "    # Make predictions\n",
    "    if choice3== 'Daily':\n",
    "        future = prophet_model.make_future_dataframe(periods=per1, freq='D')\n",
    "    elif choice3=='Monthly':\n",
    "        future = prophet_model.make_future_dataframe(periods=per1, freq='M')\n",
    "    elif choice3=='Yearly':\n",
    "        future = prophet_model.make_future_dataframe(periods=per1, freq='Y')  \n",
    "    \n",
    "    \n",
    "    forecast1 = prophet_model.predict(future)                                # forecast1 is a Pandas Dataframe\n",
    "\n",
    "    # Plot the forecast and the original time series\n",
    "    fig3 = prophet_model.plot(forecast1, uncertainty=False, figsize = (8,6) )\n",
    "\n",
    "    plt.plot(df_prophet['ds'],df_prophet['y'], label ='Original Time Series', color = 'orange')\n",
    "    plt.legend()\n",
    "    plt.title('Prophet Model Forecasting')\n",
    "    plt.xlabel(date_col)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.xticks(rotation = 45)\n",
    "\n",
    "    st.pyplot(fig3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'forecast1' in globals():\n",
    "    st. write('If the quantity being forecasted is strictly non-negative, then in case of slightly negative predicted values, assume them to be 0.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output the Dataframe of Forecast values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'forecast1' in globals():\n",
    "    df1 = pd.DataFrame(zip(forecast1['ds'][len(time_series):], forecast1['yhat'][len(time_series):]))\n",
    "    df1.columns = [date_col,'Prophet Values']\n",
    "    df1[date_col] = df1[date_col].dt.date           # remove the time part to keep just the date\n",
    "    df1['Prophet Values'] = df1['Prophet Values'].round(3)\n",
    "    \n",
    "    df1.columns = [date_col,f'Prophet Values for {ylab}']\n",
    "    \n",
    "    st.subheader(\"Dataframe of Forecasted values using Prophet\")\n",
    "    st.dataframe(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMAX Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'confirm_choice' in globals() and confirm_choice=='Yes':\n",
    "    st.header('Forecasting using SARIMAX Model')\n",
    "    \n",
    "    per2 = st.slider('Please choose the number of periods for which SARIMAX Forecasting is to be done', min_value=0, max_value=50, value = 12)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'confirm_choice' in globals() and confirm_choice=='Yes':\n",
    "    # Fit SARIMAX model (the optimal order hasn’t been decided and an arbitrary order is being used currently.)\n",
    "    sarima_model = SARIMAX(time_series, order=(0,1,2), seasonal_order= (0,0,1,12), trend='n')\n",
    "    sarima_result = sarima_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the Forecast values and then Plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'confirm_choice' in globals() and confirm_choice=='Yes':\n",
    "    # Make predictions\n",
    "    forecast_steps = per2\n",
    "    forecast2 = sarima_result.forecast(steps=forecast_steps)        # forecast2 is a Pandas Series\n",
    "    \n",
    "    fig4 = plt.figure(figsize=(8,6))\n",
    "    plt.plot(time_series, label = \"Original Time Series\", color = 'orange')\n",
    "    plt.plot(forecast2, label = \"Forecast\", color = 'blue')\n",
    "    plt.title(f'SARIMAX Model Forecasting')\n",
    "    plt.xlabel(date_col)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.legend()\n",
    "    \n",
    "    st.pyplot(fig4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'forecast2' in globals():\n",
    "    st. write('If the quantity being forecasted is strictly non-negative, then in case of slightly negative predicted values, assume them to be 0.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output the Dataframe of Forecast values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'forecast2' in globals():\n",
    "    df2 = pd.DataFrame(zip(forecast2.index,forecast2))\n",
    "    df2.columns = [date_col,'SARIMAX Values']\n",
    "    df2[date_col] = df2[date_col].dt.date                        # remove the time part to keep just the date\n",
    "    df2['SARIMAX Values'] = df2['SARIMAX Values'].round(3)\n",
    "    \n",
    "    df2.columns = [date_col,f'SARIMAX Values for {ylab}']\n",
    "    \n",
    "    st.subheader(\"Dataframe of Forecasted values using SARIMAX\")\n",
    "    st.dataframe(df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
